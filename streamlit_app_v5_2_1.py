"""
Streamlit UI for Delegator v5.2.1
å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œçŠ¶æ…‹ç›£è¦–å‹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»ã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime
import sys
import os
import time
import psutil

# ãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from delegator_v5_2_1 import OptSeqSchedulerScalable, State, Task, Equipment
except ImportError:
    st.error("delegator_v5_2_1.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Delegator v5.2.1 - å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸš€ Delegator v5.2.1: å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»ã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("**OptSeqãƒ™ãƒ¼ã‚¹ä¸¦åˆ—å‡¦ç†å¯¾å¿œ - æœ€å¤§1331éŠå…·ã¾ã§å¯¾å¿œ**")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.title("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
st.sidebar.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ")
dataset_option = st.sidebar.selectbox(
    "ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
    [
        "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)",
        "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)", 
        "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)",
        "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)"
    ],
    index=1
)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¿œã˜ãŸãƒ•ã‚¡ã‚¤ãƒ«åã¨max_equipmentè¨­å®š
dataset_config = {
    "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": {
        "equipment_file": "input_park_playequipment.csv",
        "inspection_file": "inspectionList_parkEquipment.csv",
        "max_equipment": 10
    },
    "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": {
        "equipment_file": "input_park_playequipment_100.csv",
        "inspection_file": "inspectionList_parkEquipment_100.csv",
        "max_equipment": 150
    },
    "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": {
        "equipment_file": "input_park_playequipment_100.csv",
        "inspection_file": "inspectionList_parkEquipment_100.csv",
        "max_equipment": 500
    },
    "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": {
        "equipment_file": "input_park_playequipment_241.csv",
        "inspection_file": "inspectionList_parkEquipment_1331.csv",
        "max_equipment": 1500
    }
}

config = dataset_config[dataset_option]

# è¨ˆç”»æœŸé–“è¨­å®š
start_year = st.sidebar.number_input("é–‹å§‹å¹´", min_value=2025, max_value=2030, value=2025)
end_year = st.sidebar.number_input("çµ‚äº†å¹´", min_value=2030, max_value=2050, value=2040)

# åˆ¶ç´„æ¡ä»¶è¨­å®šï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¦æ¨¡ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ï¼‰
st.sidebar.subheader("åˆ¶ç´„æ¡ä»¶")

# äºˆç®—ã®è‡ªå‹•èª¿æ•´
base_budget = {
    "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": 2000000,
    "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": 4000000,
    "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": 18000000,
    "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": 50000000
}

base_capacity = {
    "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": 5,
    "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": 20,
    "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": 80,
    "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": 200
}

annual_budget = st.sidebar.number_input(
    "å¹´é–“äºˆç®—ï¼ˆå††ï¼‰", 
    min_value=1000000, 
    value=base_budget[dataset_option], 
    step=1000000
)
annual_capacity = st.sidebar.number_input(
    "å¹´é–“æ–½å·¥å¯èƒ½ä»¶æ•°", 
    min_value=1, 
    value=base_capacity[dataset_option], 
    step=5
)

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥
strategy = st.sidebar.selectbox(
    "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥",
    ["greedy_priority", "cost_optimal", "penalty_minimization"],
    index=0
)

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
st.sidebar.subheader("ğŸ”§ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š")
enable_parallel = st.sidebar.checkbox("ä¸¦åˆ—å‡¦ç†ã‚’æœ‰åŠ¹åŒ–", value=True)
show_performance = st.sidebar.checkbox("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°ã‚’è¡¨ç¤º", value=True)

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
if show_performance:
    st.sidebar.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    st.sidebar.write(f"CPU: {psutil.cpu_count()}ã‚³ã‚¢")
    memory_gb = psutil.virtual_memory().total / (1024**3)
    st.sidebar.write(f"ãƒ¡ãƒ¢ãƒª: {memory_gb:.1f}GB")
    memory_available = psutil.virtual_memory().available / (1024**3)
    st.sidebar.write(f"åˆ©ç”¨å¯èƒ½: {memory_available:.1f}GB")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸš€ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ", type="primary"):
    st.session_state.execute_scheduling = True
    st.session_state.dataset_option = dataset_option

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š è¨­å‚™çŠ¶æ³", 
    "ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœ", 
    "ğŸ“ˆ ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ", 
    "âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", 
    "ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ"
])

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°
@st.cache_data
def load_scheduler_data(dataset_option, start_year, end_year):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¿œã˜ãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–"""
    config = dataset_config[dataset_option]
    
    scheduler = OptSeqSchedulerScalable(
        start_year, 
        end_year, 
        max_equipment=config["max_equipment"]
    )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    equipment_file = config["equipment_file"]
    inspection_file = config["inspection_file"]
    
    if os.path.exists(equipment_file) and os.path.exists(inspection_file):
        try:
            start_time = time.time()
            scheduler.load_equipment_data(equipment_file, inspection_file)
            load_time = time.time() - start_time
            return scheduler, load_time, None
        except Exception as e:
            return None, 0, str(e)
    else:
        error_msg = f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {equipment_file}, {inspection_file}"
        return None, 0, error_msg

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
scheduler, load_time, error_msg = load_scheduler_data(dataset_option, start_year, end_year)

if scheduler is None:
    st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {error_msg}")
    st.stop()

# èª­ã¿è¾¼ã¿æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if show_performance:
    st.success(f"âœ… {dataset_option} èª­ã¿è¾¼ã¿å®Œäº† - {len(scheduler.equipment)}è¨­å‚™ã€{len(scheduler.tasks)}ã‚¿ã‚¹ã‚¯ï¼ˆ{load_time:.3f}ç§’ï¼‰")

# Tab1: è¨­å‚™çŠ¶æ³
with tab1:
    st.header(f"ğŸï¸ å…¬åœ’éŠå…·ã®çŠ¶æ³ - {dataset_option}")
    
    # è¨­å‚™æ¦‚è¦
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·è¨­å‚™æ•°", len(scheduler.equipment))
    
    with col2:
        high_priority_count = sum(1 for eq in scheduler.equipment.values() 
                                 if eq.current_state and eq.current_state.grade in ['d', 'e'])
        st.metric("ç·Šæ€¥å¯¾å¿œå¿…è¦", high_priority_count, delta="å„ªå…ˆåº¦D,E")
    
    with col3:
        total_repair_cost = sum(eq.repair_cost for eq in scheduler.equipment.values())
        st.metric("ç·ä¿®ç¹•ã‚³ã‚¹ãƒˆ", f"Â¥{total_repair_cost:,.0f}")
    
    with col4:
        if scheduler.equipment:
            avg_age = sum(2025 - eq.install_year for eq in scheduler.equipment.values()) / len(scheduler.equipment)
            st.metric("å¹³å‡ç¯‰å¹´æ•°", f"{avg_age:.1f}å¹´")
        else:
            st.metric("å¹³å‡ç¯‰å¹´æ•°", "N/A")
    
    # åŠ£åŒ–çŠ¶æ…‹åˆ†å¸ƒ
    st.subheader("åŠ£åŒ–çŠ¶æ…‹åˆ†å¸ƒ")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    equipment_data = []
    for eq in scheduler.equipment.values():
        if eq.current_state:
            equipment_data.append({
                'è¨­å‚™ID': eq.id,
                'å…¬åœ’å': eq.park_name,
                'è¨­å‚™ç¨®é¡': eq.equipment_type,
                'è¨­ç½®å¹´': eq.install_year,
                'ç¯‰å¹´æ•°': 2025 - eq.install_year,
                'åŠ£åŒ–åˆ¤å®š': eq.current_state.grade.upper(),
                'åŠ£åŒ–ã‚¹ã‚³ã‚¢': eq.current_state.score,
                'ä¿®ç¹•ã‚³ã‚¹ãƒˆ': eq.repair_cost
            })
    
    equipment_df = pd.DataFrame(equipment_data)
    
    if not equipment_df.empty:
        # åŠ£åŒ–çŠ¶æ…‹ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        col1, col2 = st.columns(2)
        
        with col1:
            grade_counts = equipment_df['åŠ£åŒ–åˆ¤å®š'].value_counts()
            fig_bar = px.bar(
                x=grade_counts.index,
                y=grade_counts.values,
                title="åŠ£åŒ–åˆ¤å®šã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ",
                labels={'x': 'åŠ£åŒ–åˆ¤å®š', 'y': 'è¨­å‚™æ•°'},
                color=grade_counts.values,
                color_continuous_scale='Reds'
            )
            st.plotly_chart(fig_bar, use_container_width=True)
        
        with col2:
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ1000ä»¶ä»¥ä¸Šã®å ´åˆï¼‰
            display_df = equipment_df.sample(min(1000, len(equipment_df))) if len(equipment_df) > 1000 else equipment_df
            
            fig_scatter = px.scatter(
                display_df,
                x='ç¯‰å¹´æ•°',
                y='åŠ£åŒ–ã‚¹ã‚³ã‚¢',
                color='åŠ£åŒ–åˆ¤å®š',
                size='ä¿®ç¹•ã‚³ã‚¹ãƒˆ',
                hover_data=['å…¬åœ’å', 'è¨­å‚™ç¨®é¡'],
                title=f"ç¯‰å¹´æ•°ã¨åŠ£åŒ–ã‚¹ã‚³ã‚¢ã®é–¢ä¿‚ {'(ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º)' if len(equipment_df) > 1000 else ''}"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        st.subheader("çµ±è¨ˆã‚µãƒãƒªãƒ¼")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write("**åŠ£åŒ–åˆ¤å®šåˆ†å¸ƒ**")
            for grade, count in grade_counts.items():
                percentage = (count / len(equipment_df)) * 100
                st.write(f"{grade}: {count}ä»¶ ({percentage:.1f}%)")
        
        with col2:
            st.write("**ç¯‰å¹´æ•°çµ±è¨ˆ**")
            st.write(f"æœ€å°: {equipment_df['ç¯‰å¹´æ•°'].min()}å¹´")
            st.write(f"æœ€å¤§: {equipment_df['ç¯‰å¹´æ•°'].max()}å¹´")
            st.write(f"å¹³å‡: {equipment_df['ç¯‰å¹´æ•°'].mean():.1f}å¹´")
            st.write(f"ä¸­å¤®å€¤: {equipment_df['ç¯‰å¹´æ•°'].median():.1f}å¹´")
        
        with col3:
            st.write("**ã‚³ã‚¹ãƒˆçµ±è¨ˆ**")
            st.write(f"æœ€å°: Â¥{equipment_df['ä¿®ç¹•ã‚³ã‚¹ãƒˆ'].min():,.0f}")
            st.write(f"æœ€å¤§: Â¥{equipment_df['ä¿®ç¹•ã‚³ã‚¹ãƒˆ'].max():,.0f}")
            st.write(f"å¹³å‡: Â¥{equipment_df['ä¿®ç¹•ã‚³ã‚¹ãƒˆ'].mean():,.0f}")
            st.write(f"åˆè¨ˆ: Â¥{equipment_df['ä¿®ç¹•ã‚³ã‚¹ãƒˆ'].sum():,.0f}")
        
        # è¨­å‚™ä¸€è¦§è¡¨ï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°å¯¾å¿œï¼‰
        st.subheader("è¨­å‚™è©³ç´°ä¸€è¦§")
        
        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãƒšãƒ¼ã‚¸ãƒ³ã‚°
        if len(equipment_df) > 100:
            st.write(f"ç·ä»¶æ•°: {len(equipment_df)}ä»¶")
            page_size = 100
            total_pages = (len(equipment_df) - 1) // page_size + 1
            page = st.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", range(1, total_pages + 1))
            
            start_idx = (page - 1) * page_size
            end_idx = min(start_idx + page_size, len(equipment_df))
            display_df = equipment_df.iloc[start_idx:end_idx]
            
            st.write(f"è¡¨ç¤º: {start_idx + 1} - {end_idx} / {len(equipment_df)}")
            st.dataframe(display_df, use_container_width=True)
        else:
            st.dataframe(equipment_df, use_container_width=True)
    else:
        st.warning("è¨­å‚™ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# Tab2: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœ
with tab2:
    st.header("ğŸ“… æœ€é©åŒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœ")
    
    if 'execute_scheduling' in st.session_state and st.session_state.execute_scheduling:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®è­¦å‘Š
        if 'dataset_option' in st.session_state and st.session_state.dataset_option != dataset_option:
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™ã€‚å†åº¦å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.execute_scheduling = False
        else:
            with st.spinner(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æœ€é©åŒ–ä¸­... ({dataset_option})"):
                try:
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šé–‹å§‹
                    start_time = time.time()
                    start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                    
                    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ
                    if enable_parallel:
                        result = scheduler.solve_parallel(strategy)
                    else:
                        result = scheduler.solve(strategy)
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµ‚äº†
                    end_time = time.time()
                    end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                    
                    execution_time = end_time - start_time
                    memory_usage = end_memory - start_memory
                    
                    # çµæœã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ä¿å­˜
                    st.session_state.schedule_result = result
                    st.session_state.performance_info = {
                        'execution_time': execution_time,
                        'memory_usage': memory_usage,
                        'parallel_enabled': enable_parallel,
                        'dataset_size': len(scheduler.equipment)
                    }
                    st.session_state.execute_scheduling = False
                    
                    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if show_performance:
                        st.success(f"âœ… æœ€é©åŒ–å®Œäº†! å®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.1f}MB")
                
                except Exception as e:
                    st.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.session_state.execute_scheduling = False
    
    if 'schedule_result' in st.session_state:
        result = st.session_state.schedule_result
        
        # çµ±è¨ˆæƒ…å ±
        stats = result['statistics']
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆ", f"{stats['scheduled_tasks']}/{stats['total_tasks']}")
        
        with col2:
            st.metric("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{stats['total_cost']:,.0f}")
        
        with col3:
            # ç¾å®Ÿçš„ãªãƒšãƒŠãƒ«ãƒ†ã‚£è¡¨ç¤º
            penalty_million = stats['total_penalty'] / 1000000
            st.metric("é…å»¶ãƒšãƒŠãƒ«ãƒ†ã‚£", f"Â¥{penalty_million:.1f}M", help="ç¾å®Ÿçš„ãªä¿é™ºæ”¯æ‰•é¡ãƒ¬ãƒ™ãƒ«")
        
        with col4:
            scheduling_rate = stats['scheduling_ratio'] * 100
            st.metric("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æˆåŠŸç‡", f"{scheduling_rate:.1f}%")
        
        with col5:
            if 'performance_info' in st.session_state:
                perf = st.session_state.performance_info
                throughput = perf['dataset_size'] / perf['execution_time']
                st.metric("å‡¦ç†é€Ÿåº¦", f"{throughput:.0f}è¨­å‚™/ç§’")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°
        if show_performance and 'performance_info' in st.session_state:
            st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°")
            perf = st.session_state.performance_info
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.write(f"**å®Ÿè¡Œæ™‚é–“**: {perf['execution_time']:.3f}ç§’")
            with col2:
                st.write(f"**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: {perf['memory_usage']:.1f}MB")
            with col3:
                st.write(f"**ä¸¦åˆ—å‡¦ç†**: {'æœ‰åŠ¹' if perf['parallel_enabled'] else 'ç„¡åŠ¹'}")
            with col4:
                throughput = perf['dataset_size'] / perf['execution_time']
                st.write(f"**ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: {throughput:.0f}è¨­å‚™/ç§’")
        
        # å¹´åº¦åˆ¥äºˆç®—ãƒ»ä»¶æ•°
        col1, col2 = st.columns(2)
        
        with col1:
            annual_cost_df = pd.DataFrame([
                {'å¹´åº¦': year, 'ã‚³ã‚¹ãƒˆ': cost} 
                for year, cost in result['annual_cost'].items()
            ])
            fig_cost = px.bar(
                annual_cost_df,
                x='å¹´åº¦',
                y='ã‚³ã‚¹ãƒˆ',
                title="å¹´åº¦åˆ¥ä¿®ç¹•ã‚³ã‚¹ãƒˆ",
                labels={'ã‚³ã‚¹ãƒˆ': 'ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰'}
            )
            fig_cost.add_hline(y=annual_budget, line_dash="dash", line_color="red", 
                              annotation_text="äºˆç®—ä¸Šé™")
            st.plotly_chart(fig_cost, use_container_width=True)
        
        with col2:
            annual_count_df = pd.DataFrame([
                {'å¹´åº¦': year, 'ä»¶æ•°': count} 
                for year, count in result['annual_count'].items()
            ])
            fig_count = px.bar(
                annual_count_df,
                x='å¹´åº¦',
                y='ä»¶æ•°',
                title="å¹´åº¦åˆ¥æ–½å·¥ä»¶æ•°",
                labels={'ä»¶æ•°': 'æ–½å·¥ä»¶æ•°'}
            )
            fig_count.add_hline(y=annual_capacity, line_dash="dash", line_color="red",
                               annotation_text="èƒ½åŠ›ä¸Šé™")
            st.plotly_chart(fig_count, use_container_width=True)
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°è¡¨
        st.subheader("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°")
        schedule_data = []
        for task_id, task_data in result['schedule'].items():
            # è¨­å‚™IDã®å®‰å…¨ãªå–å¾—
            equipment_id = task_data['equipment_id']
            if equipment_id not in scheduler.equipment:
                st.warning(f"è¨­å‚™ID {equipment_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
                
            equipment = scheduler.equipment[equipment_id]
            state = equipment.current_state
            
            schedule_data.append({
                'å…¬åœ’å': equipment.park_name,
                'è¨­å‚™ç¨®é¡': equipment.equipment_type,
                'åŠ£åŒ–åˆ¤å®š': state.grade.upper() if state else 'N/A',
                'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å¹´': task_data['scheduled_year'],
                'å„ªå…ˆåº¦': task_data['priority'],
                'ã‚³ã‚¹ãƒˆ': f"Â¥{task_data['cost']:,.0f}",
                'é…å»¶å¹´æ•°': task_data['delay_years'],
                'ãƒšãƒŠãƒ«ãƒ†ã‚£': f"Â¥{task_data['penalty']:,.0f}"
            })
        
        schedule_df = pd.DataFrame(schedule_data)
        
        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãƒšãƒ¼ã‚¸ãƒ³ã‚°
        if len(schedule_df) > 50:
            st.write(f"ç·ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä»¶æ•°: {len(schedule_df)}ä»¶")
            page_size = 50
            total_pages = (len(schedule_df) - 1) // page_size + 1
            page = st.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", range(1, total_pages + 1), key="schedule_page")
            
            start_idx = (page - 1) * page_size
            end_idx = min(start_idx + page_size, len(schedule_df))
            display_schedule_df = schedule_df.iloc[start_idx:end_idx]
            
            st.write(f"è¡¨ç¤º: {start_idx + 1} - {end_idx} / {len(schedule_df)}")
            st.dataframe(display_schedule_df, use_container_width=True)
        else:
            st.dataframe(schedule_df, use_container_width=True)
    
    else:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

# Tab3: ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ
with tab3:
    st.header("ğŸ“ˆ ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ")
    
    if 'schedule_result' in st.session_state:
        result = st.session_state.schedule_result
        gantt_data = scheduler.export_gantt_data(result)
        
        if gantt_data:
            # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯è¡¨ç¤ºä»¶æ•°ã‚’åˆ¶é™
            max_display = 200
            if len(gantt_data) > max_display:
                st.warning(f"âš ï¸ è¡¨ç¤ºä»¶æ•°åˆ¶é™: {len(gantt_data)}ä»¶ä¸­{max_display}ä»¶ã‚’è¡¨ç¤º")
                # å„ªå…ˆåº¦ã®é«˜ã„ã‚‚ã®é †ã«ã‚½ãƒ¼ãƒˆ
                gantt_data_sorted = sorted(gantt_data, key=lambda x: x['Priority'], reverse=True)
                gantt_data_display = gantt_data_sorted[:max_display]
            else:
                gantt_data_display = gantt_data
            
            # Plotlyã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ
            fig = go.Figure()
            
            colors = {'A': 'green', 'B': 'blue', 'C': 'orange', 'D': 'red', 'E': 'darkred'}
            
            for i, task in enumerate(gantt_data_display):
                grade = task['Resource'].split('-')[1]
                color = colors.get(grade, 'gray')
                
                fig.add_trace(go.Scatter(
                    x=[task['Start'], task['Finish']],
                    y=[i, i],
                    mode='lines+markers',
                    line=dict(color=color, width=8),
                    name=f"{task['Task'][:30]}... ({grade})" if len(task['Task']) > 30 else f"{task['Task']} ({grade})",
                    hovertemplate=f"""
                    <b>{task['Task']}</b><br>
                    å¹´åº¦: {task['Start']}<br>
                    åŠ£åŒ–åˆ¤å®š: {grade}<br>
                    ã‚³ã‚¹ãƒˆ: Â¥{task['Cost']:,.0f}<br>
                    å„ªå…ˆåº¦: {task['Priority']}<br>
                    ãƒšãƒŠãƒ«ãƒ†ã‚£: Â¥{task['Penalty']:,.0f}
                    <extra></extra>
                    """
                ))
            
            fig.update_layout(
                title=f"ä¿®ç¹•ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ ({len(gantt_data_display)}ä»¶è¡¨ç¤º)",
                xaxis_title="å¹´åº¦",
                yaxis_title="è¨­å‚™",
                yaxis=dict(
                    tickmode='array',
                    tickvals=list(range(len(gantt_data_display))),
                    ticktext=[f"{i+1}. {task['Task'][:20]}..." if len(task['Task']) > 20 
                             else f"{i+1}. {task['Task']}" 
                             for i, task in enumerate(gantt_data_display)]
                ),
                height=max(400, min(len(gantt_data_display) * 25, 1200)),
                showlegend=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # åŠ£åŒ–åˆ¤å®šåˆ¥ã®å‡¡ä¾‹
            st.subheader("åŠ£åŒ–åˆ¤å®šå‡¡ä¾‹")
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.markdown("ğŸŸ¢ **Aåˆ¤å®š**: è‰¯å¥½")
            with col2:
                st.markdown("ğŸ”µ **Båˆ¤å®š**: ã‚„ã‚„åŠ£åŒ–")
            with col3:
                st.markdown("ğŸŸ  **Cåˆ¤å®š**: 1å¹´ä»¥å†…")
            with col4:
                st.markdown("ğŸ”´ **Dåˆ¤å®š**: 3ãƒ¶æœˆä»¥å†…")
            with col5:
                st.markdown("ğŸ”´ **Eåˆ¤å®š**: ç·Šæ€¥å¯¾å¿œ")
            
            # çµ±è¨ˆæƒ…å ±
            if len(gantt_data) != len(gantt_data_display):
                st.info(f"ğŸ“Š å…¨{len(gantt_data)}ä»¶ä¸­ã€å„ªå…ˆåº¦ä¸Šä½{len(gantt_data_display)}ä»¶ã‚’è¡¨ç¤ºä¸­")
        
        else:
            st.warning("ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    else:
        st.info("ã¾ãšã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# Tab4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
with tab4:
    st.header("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
    
    if 'schedule_result' in st.session_state and 'performance_info' in st.session_state:
        result = st.session_state.schedule_result
        perf = st.session_state.performance_info
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
        st.subheader("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å®Ÿè¡Œæ™‚é–“", f"{perf['execution_time']:.3f}ç§’")
            st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{perf['memory_usage']:.1f}MB")
        
        with col2:
            throughput = perf['dataset_size'] / perf['execution_time']
            st.metric("å‡¦ç†é€Ÿåº¦", f"{throughput:.0f}è¨­å‚™/ç§’")
            st.metric("ä¸¦åˆ—å‡¦ç†", "æœ‰åŠ¹" if perf['parallel_enabled'] else "ç„¡åŠ¹")
        
        with col3:
            efficiency = perf['dataset_size'] / (perf['memory_usage'] if perf['memory_usage'] > 0 else 1)
            st.metric("ãƒ¡ãƒ¢ãƒªåŠ¹ç‡", f"{efficiency:.0f}è¨­å‚™/MB")
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¦æ¨¡", f"{perf['dataset_size']}è¨­å‚™")
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ¯”è¼ƒ
        st.subheader("ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ¯”è¼ƒ")
        
        # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
        baseline_performance = {
            "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": {"time": 1.2, "memory": 1.3},
            "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": {"time": 0.071, "memory": 0.1},
            "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": {"time": 0.0, "memory": 0.0},  # å®Ÿæ¸¬å€¤ã‚’æ›´æ–°
            "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": {"time": 1.946, "memory": 0.9}
        }
        
        current_dataset = st.session_state.get('dataset_option', dataset_option)
        
        if current_dataset in baseline_performance:
            baseline = baseline_performance[current_dataset]
            
            col1, col2 = st.columns(2)
            
            with col1:
                if baseline["time"] > 0 and perf['execution_time'] > 0:
                    time_efficiency = baseline["time"] / perf['execution_time']
                    st.metric(
                        "æ™‚é–“åŠ¹ç‡", 
                        f"{time_efficiency:.2f}x",
                        help="ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ (>1.0ãŒé«˜åŠ¹ç‡)"
                    )
                else:
                    st.metric("æ™‚é–“åŠ¹ç‡", "åˆå›æ¸¬å®š")
            
            with col2:
                if baseline["memory"] > 0 and perf['memory_usage'] > 0:
                    memory_efficiency = baseline["memory"] / perf['memory_usage']
                    st.metric(
                        "ãƒ¡ãƒ¢ãƒªåŠ¹ç‡", 
                        f"{memory_efficiency:.2f}x",
                        help="ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ (>1.0ãŒé«˜åŠ¹ç‡)"
                    )
                else:
                    st.metric("ãƒ¡ãƒ¢ãƒªåŠ¹ç‡", "åˆå›æ¸¬å®š")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ©ãƒ•
        st.subheader("ğŸ“Š å‡¦ç†æ™‚é–“å†…è¨³")
        
        if 'performance' in result:
            perf_data = result['performance']
            
            # å‡¦ç†æ™‚é–“ã®å†…è¨³
            breakdown_data = {
                'ãƒ•ã‚§ãƒ¼ã‚º': ['ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿', 'æœ€é©åŒ–å®Ÿè¡Œ'],
                'æ™‚é–“(ç§’)': [
                    perf_data.get('load_time', 0),
                    perf_data.get('solve_time', 0)
                ]
            }
            
            fig_breakdown = px.bar(
                breakdown_data,
                x='ãƒ•ã‚§ãƒ¼ã‚º',
                y='æ™‚é–“(ç§’)',
                title="å‡¦ç†æ™‚é–“å†…è¨³",
                color='æ™‚é–“(ç§’)',
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig_breakdown, use_container_width=True)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
        st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            cpu_percent = psutil.cpu_percent(interval=1)
            st.metric("CPUä½¿ç”¨ç‡", f"{cpu_percent:.1f}%")
            
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{memory_percent:.1f}%")
        
        with col2:
            available_memory = memory.available / (1024**3)
            st.metric("åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª", f"{available_memory:.1f}GB")
            
            cpu_cores = psutil.cpu_count()
            st.metric("CPUã‚³ã‚¢æ•°", f"{cpu_cores}ã‚³ã‚¢")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        st.subheader("ğŸ† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡")
        
        # è©•ä¾¡åŸºæº–
        score = 0
        evaluations = []
        
        # å‡¦ç†æ™‚é–“è©•ä¾¡
        time_thresholds = {
            "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": 5,
            "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": 5,
            "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": 10,
            "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": 30
        }
        
        time_threshold = time_thresholds.get(current_dataset, 10)
        if perf['execution_time'] <= time_threshold:
            evaluations.append("â±ï¸ å‡¦ç†æ™‚é–“: â—¯")
            score += 1
        else:
            evaluations.append("â±ï¸ å‡¦ç†æ™‚é–“: â–³")
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡è©•ä¾¡
        memory_thresholds = {
            "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (5è¨­å‚™)": 10,
            "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (100è¨­å‚™)": 100,
            "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (457éŠå…·)": 500,
            "è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ (1331éŠå…·)": 1000
        }
        
        memory_threshold = memory_thresholds.get(current_dataset, 100)
        if perf['memory_usage'] <= memory_threshold:
            evaluations.append("ğŸ’¾ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: â—¯")
            score += 1
        else:
            evaluations.append("ğŸ’¾ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: â–³")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè©•ä¾¡
        throughput = perf['dataset_size'] / perf['execution_time']
        if throughput >= 100:  # 100è¨­å‚™/ç§’ä»¥ä¸Š
            evaluations.append("ğŸš€ å‡¦ç†é€Ÿåº¦: â—¯")
            score += 1
        else:
            evaluations.append("ğŸš€ å‡¦ç†é€Ÿåº¦: â–³")
        
        # ç·åˆè©•ä¾¡
        rating = ["D", "C", "B", "A", "S"][min(score, 4)]
        
        st.success(f"**ç·åˆè©•ä¾¡: {rating}ãƒ©ãƒ³ã‚¯ ({score}/3)**")
        for evaluation in evaluations:
            st.write(evaluation)
    
    else:
        st.info("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# Tab5: è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
with tab5:
    st.header("ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
    
    if 'schedule_result' in st.session_state:
        result = st.session_state.schedule_result
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚µãƒãƒªãƒ¼
        st.subheader("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚µãƒãƒªãƒ¼")
        
        report_summary = {
            "ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³": "v5.2.1",
            "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": dataset_option,
            "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥": strategy,
            "è¨ˆç”»æœŸé–“": f"{start_year}-{end_year}",
            "ç·è¨­å‚™æ•°": len(scheduler.equipment),
            "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆã‚¿ã‚¹ã‚¯": result['statistics']['scheduled_tasks'],
            "æˆåŠŸç‡": f"{result['statistics']['scheduling_ratio']*100:.1f}%",
            "ç·ã‚³ã‚¹ãƒˆ": f"Â¥{result['statistics']['total_cost']:,.0f}",
            "ç·ãƒšãƒŠãƒ«ãƒ†ã‚£": f"Â¥{result['statistics']['total_penalty']:,.0f}",
            "å®Ÿè¡Œæ—¥æ™‚": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        for key, value in report_summary.items():
            st.write(f"**{key}**: {value}")
        
        # JSONå‡ºåŠ›
        st.subheader("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœï¼ˆJSONï¼‰")
        with st.expander("JSON ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
            st.json(result)
        
        # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.subheader("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“¥ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                schedule_data = []
                for task_id, task_data in result['schedule'].items():
                    equipment_id = task_data['equipment_id']
                    if equipment_id not in scheduler.equipment:
                        continue  # è¦‹ã¤ã‹ã‚‰ãªã„è¨­å‚™IDã¯ã‚¹ã‚­ãƒƒãƒ—
                        
                    equipment = scheduler.equipment[equipment_id]
                    state = equipment.current_state
                    
                    schedule_data.append({
                        'task_id': task_id,
                        'equipment_id': task_data['equipment_id'],
                        'park_name': equipment.park_name,
                        'equipment_type': equipment.equipment_type,
                        'install_year': equipment.install_year,
                        'degradation_grade': state.grade.upper() if state else 'N/A',
                        'degradation_score': state.score if state else 0,
                        'scheduled_year': task_data['scheduled_year'],
                        'priority': task_data['priority'],
                        'cost': task_data['cost'],
                        'delay_years': task_data['delay_years'],
                        'penalty': task_data['penalty']
                    })
                
                schedule_csv = pd.DataFrame(schedule_data)
                csv_string = schedule_csv.to_csv(index=False, encoding='utf-8-sig')
                
                st.download_button(
                    label="ğŸ“¥ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_string,
                    file_name=f"delegator_v5.2.1_schedule_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        with col2:
            if st.button("ğŸ“¥ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                if 'performance_info' in st.session_state:
                    performance_report = {
                        "system_info": {
                            "version": "v5.2.1",
                            "dataset": dataset_option,
                            "timestamp": datetime.now().isoformat()
                        },
                        "performance": st.session_state.performance_info,
                        "results": {
                            "scheduled_tasks": result['statistics']['scheduled_tasks'],
                            "total_tasks": result['statistics']['total_tasks'],
                            "success_rate": result['statistics']['scheduling_ratio'],
                            "total_cost": result['statistics']['total_cost'],
                            "total_penalty": result['statistics']['total_penalty']
                        }
                    }
                    
                    json_string = json.dumps(performance_report, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ğŸ“¥ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=json_string,
                        file_name=f"delegator_v5.2.1_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        system_info = {
            "ãƒãƒ¼ã‚¸ãƒ§ãƒ³": "v5.2.1 (å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ)",
            "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": dataset_option,
            "æœ€å¤§å¯¾å¿œè¨­å‚™æ•°": config["max_equipment"],
            "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥": strategy,
            "ä¸¦åˆ—å‡¦ç†": "æœ‰åŠ¹" if enable_parallel else "ç„¡åŠ¹",
            "è¨ˆç”»æœŸé–“": f"{start_year}-{end_year}",
            "å¹´é–“äºˆç®—": f"Â¥{annual_budget:,.0f}",
            "å¹´é–“æ–½å·¥èƒ½åŠ›": f"{annual_capacity}ä»¶",
            "ã‚·ã‚¹ãƒ†ãƒ CPU": f"{psutil.cpu_count()}ã‚³ã‚¢",
            "ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª": f"{psutil.virtual_memory().total / (1024**3):.1f}GB",
            "Pythonç’°å¢ƒ": f"Python {sys.version.split()[0]}",
            "å®Ÿè¡Œæ—¥æ™‚": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        for key, value in system_info.items():
            st.write(f"**{key}**: {value}")
    
    else:
        st.info("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("**Delegator v5.2.1** - å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œçŠ¶æ…‹ç›£è¦–å‹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»ã‚·ã‚¹ãƒ†ãƒ  | Powered by OptSeq & Streamlit")
st.markdown("æœ€å¤§1331éŠå…·å¯¾å¿œ | ä¸¦åˆ—å‡¦ç†å¯¾å¿œ | ç¾å®Ÿçš„ãƒšãƒŠãƒ«ãƒ†ã‚£è¨­å®š")
